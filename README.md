# Fusion Pose: A Mediapipe and Keypoint R-CNN Fused Model for Enhanced Cyclist Pose Estimation and Injury Risk Prediction

This project implements a fusion-based pose estimation system using **MediaPipe** and **Keypoint R-CNN** to improve the accuracy of cyclist posture analysis. It calculates joint angles and predicts injury risk levels using machine learning models like XGBoost.

---

## ğŸ” Overview

Cyclists often experience posture-related injuries due to incorrect riding positions. This project enhances injury risk prediction by fusing outputs from multiple pose estimation models and analyzing joint-level movement patterns.

The pipeline includes:
- Keypoint detection (multiple DL models)
- Feature fusion
- Joint angle computation (hip, knee, elbow)
- Injury risk classification
- Validation using ground truth and multiple performance metrics

---

## ğŸ§  Models & Techniques

- **Pose Estimators**:
  - MediaPipe
  - Keypoint R-CNN (TorchVision)
  - YOLOPose
  - MoveNet

- **Fusion Model**: Confidence-based merging of keypoints from different detectors

- **Risk Prediction**: XGBoost classifier trained on angle features

- **Validation Metrics**:
  - Mean Absolute Error (MAE)
  - Mean Squared Error (MSE)
  - Root Mean Squared Error (RMSE)
  - Percentage of Correct Keypoints (PCK)
  - Mean Joint Position Error (MJPE)
  - Euclidean Distance

---

## âš™ï¸ Technologies Used

- Python
- Torch / TorchVision
- OpenCV
- MediaPipe
- XGBoost
- NumPy
- Matplotlib
- scikit-learn
- Jupyter Notebooks

---

## ğŸ› ï¸ Key Features

- Extracts 2D keypoints from cycling videos using DL models
- Combines outputs of MediaPipe and Keypoint R-CNN for enhanced accuracy
- Calculates biomechanical joint angles
- Predicts injury risk level (Low / Moderate / High)
- Compares results with marker-based ground truth
- Evaluates performance using industry-standard metrics

---

## ğŸ“‚ Project Structure

fusion-pose/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ angles.ipynb
â”‚ â”œâ”€â”€ euclidean_distance.ipynb
â”‚ â”œâ”€â”€ featurefusion_updated.ipynb
â”‚ â”œâ”€â”€ groundtruth.ipynb
â”‚ â”œâ”€â”€ mae.ipynb
â”‚ â”œâ”€â”€ mediapip.ipynb
â”‚ â”œâ”€â”€ mjpe.ipynb
â”‚ â”œâ”€â”€ movenet.ipynb
â”‚ â”œâ”€â”€ mseAndRmse.ipynb
â”‚ â”œâ”€â”€ pck.ipynb
â”‚ â”œâ”€â”€ risk_classification.ipynb
â”‚ â”œâ”€â”€ validation.ipynb
â”‚ â”œâ”€â”€ video_to_frame.ipynb
â”‚ â””â”€â”€ xgboost_classifier.ipynb
â”œâ”€â”€ utils/ # Helper scripts
â”œâ”€â”€ sample_videos/ # Input test videos
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


##  Getting Started

### 1. Clone the repository
git clone https://github.com/livithapoornima/Mediapipe-Keypoint-R-CNN-fused-model-for-enhanced-cyclist-pose-estimation-and-injury-risk-prediction.git
cd Mediapipe-Keypoint-R-CNN-fused-model-for-enhanced-cyclist-pose-estimation-and-injury-risk-prediction


### 2. Install dependencies

pip install -r requirements.txt


---

## ğŸ“Š Evaluation Metrics

- **MAE / MSE / RMSE** â€“ Quantitative comparison between predicted and ground-truth joint angles.
- **MJPE (Mean Joint Position Error)** â€“ Measures average error per joint keypoint.
- **PCK (Percentage of Correct Keypoints)** â€“ Evaluates how many keypoints fall within a threshold distance from ground truth.
- **Euclidean Distance** â€“ Used for keypoint-level comparison between models and fused output.
- **Confusion Matrix / Accuracy** â€“ For evaluating injury risk classification.

---

## ğŸ“¦ Dataset

The dataset includes:
- Video frames of cyclists in different postures
- Marker-based ground-truth joint annotations
- Processed keypoint data from MediaPipe, Keypoint R-CNN, YOLOPose, and MoveNet

âš ï¸ Due to size restrictions, the dataset is not stored in this repository.  

---
## ğŸ™ Acknowledgements

- **Google MediaPipe** â€“ for fast real-time pose estimation
- **TorchVision** â€“ for Keypoint R-CNN model
- **MoveNet / YOLOPose** â€“ for alternative pose extraction
- **VIT Chennai â€“ Cyclist Posture Lab** â€“ for research support and ground-truth data
- Open-source ML and CV communities for continued inspiration

---
